## Run Spark on DC/OS

Apache Spark is a general-purpose data processing engine. It supports batch and stream processing and comes with built-in APIs for SQL, machine learning and graph workloads. Spark is storage-layer agnostic, meaning it doesn't come with its own storage system but provides connectors to read data from and write data into, for example, the local filesystem, HDFS, Kafka, Cassandra, Elasticsearch, and HBase.

Continue [here](http://dcos.io/docs/usage/tutorials/spark) to learn about how to use Spark on DC/OS, from the simple first steps of how to launch a Spark job to using Spark interactively with Apache Zeppelin.
